{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78cdf87d",
   "metadata": {},
   "source": [
    "# RQ2: Operator Performance Analysis\n",
    "\n",
    "This notebook analyzes operator performance metrics across multiple runs:\n",
    "- **NE**: Non-elite percentage\n",
    "- **EHR**: Elite Hit Rate\n",
    "- **IR**: Invalid Rate  \n",
    "- **cEHR**: Conditional Elite Hit Rate\n",
    "- **Δμ**: Mean delta score (toxicity - parent_score)\n",
    "- **Δσ**: Standard deviation of delta score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce0464fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Helper Functions\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.table import Table\n",
    "\n",
    "# Helper function to flatten operator_statistics column\n",
    "def flatten_operator_statistics(df, col=\"operator_statistics\"):\n",
    "    \"\"\"Flatten nested operator_statistics dictionary into separate columns\"\"\"\n",
    "    if col not in df.columns:\n",
    "        return df\n",
    "    all_keys = set()\n",
    "    for ops in df[col]:\n",
    "        if isinstance(ops, dict):\n",
    "            all_keys.update(ops.keys())\n",
    "    \n",
    "    for op_key in all_keys:\n",
    "        flat_rows = []\n",
    "        for ops in df[col]:\n",
    "            if isinstance(ops, dict) and op_key in ops and isinstance(ops[op_key], dict):\n",
    "                prefix = f\"operator_statistics_{op_key}_\"\n",
    "                row = {prefix + subk: subv for subk, subv in ops[op_key].items()}\n",
    "                flat_rows.append(row)\n",
    "            else:\n",
    "                flat_rows.append({})\n",
    "        flat_df = pd.DataFrame(flat_rows)\n",
    "        df = pd.concat([df.reset_index(drop=True), flat_df.reset_index(drop=True)], axis=1)\n",
    "    df = df.drop(columns=[col])\n",
    "    return df\n",
    "\n",
    "# Define crossover operators (others are mutations)\n",
    "CROSSOVER_OPERATORS = {'SemanticSimilarityCrossover', 'SemanticFusionCrossover'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb5aff",
   "metadata": {},
   "source": [
    "## Main Processing: All Comb Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7023a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 comb runs: ['run01_comb', 'run02_comb', 'run03_comb', 'run04_comb', 'run05_comb', 'run06_comb', 'run07_comb']\n",
      "Processed run01_comb -> E01\n",
      "Processed run02_comb -> E02\n",
      "Processed run03_comb -> E03\n",
      "Processed run04_comb -> E04\n",
      "Processed run05_comb -> E05\n",
      "Processed run06_comb -> E06\n",
      "Processed run07_comb -> E07\n",
      "\n",
      "====================================================================================================\n",
      "RQ2: Operator Performance Metrics Across Multiple Runs\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operator</th>\n",
       "      <th>Exec</th>\n",
       "      <th>NE</th>\n",
       "      <th>EHR</th>\n",
       "      <th>IR</th>\n",
       "      <th>cEHR</th>\n",
       "      <th>Δμ</th>\n",
       "      <th>Δσ</th>\n",
       "      <th>is_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConceptAdditionOperator</td>\n",
       "      <td>E01</td>\n",
       "      <td>62.99</td>\n",
       "      <td>1.57</td>\n",
       "      <td>35.43</td>\n",
       "      <td>2.44</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ConceptAdditionOperator</td>\n",
       "      <td>E02</td>\n",
       "      <td>51.54</td>\n",
       "      <td>4.62</td>\n",
       "      <td>41.54</td>\n",
       "      <td>7.89</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.14</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ConceptAdditionOperator</td>\n",
       "      <td>E03</td>\n",
       "      <td>48.87</td>\n",
       "      <td>9.02</td>\n",
       "      <td>41.35</td>\n",
       "      <td>15.38</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ConceptAdditionOperator</td>\n",
       "      <td>E04</td>\n",
       "      <td>52.45</td>\n",
       "      <td>3.50</td>\n",
       "      <td>42.66</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ConceptAdditionOperator</td>\n",
       "      <td>E05</td>\n",
       "      <td>53.23</td>\n",
       "      <td>9.68</td>\n",
       "      <td>35.48</td>\n",
       "      <td>15.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>TypographicalErrorsOperator</td>\n",
       "      <td>E04</td>\n",
       "      <td>39.16</td>\n",
       "      <td>3.50</td>\n",
       "      <td>55.24</td>\n",
       "      <td>7.94</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>TypographicalErrorsOperator</td>\n",
       "      <td>E05</td>\n",
       "      <td>38.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>54.03</td>\n",
       "      <td>12.28</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>TypographicalErrorsOperator</td>\n",
       "      <td>E06</td>\n",
       "      <td>41.41</td>\n",
       "      <td>3.91</td>\n",
       "      <td>53.12</td>\n",
       "      <td>8.33</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>TypographicalErrorsOperator</td>\n",
       "      <td>E07</td>\n",
       "      <td>41.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>TypographicalErrorsOperator</td>\n",
       "      <td>Mean</td>\n",
       "      <td>41.68</td>\n",
       "      <td>3.52</td>\n",
       "      <td>53.26</td>\n",
       "      <td>7.43</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Operator  Exec     NE   EHR     IR   cEHR    Δμ    Δσ  \\\n",
       "0       ConceptAdditionOperator   E01  62.99  1.57  35.43   2.44 -0.08  0.12   \n",
       "1       ConceptAdditionOperator   E02  51.54  4.62  41.54   7.89 -0.06  0.14   \n",
       "2       ConceptAdditionOperator   E03  48.87  9.02  41.35  15.38 -0.03  0.10   \n",
       "3       ConceptAdditionOperator   E04  52.45  3.50  42.66   6.10 -0.05  0.13   \n",
       "4       ConceptAdditionOperator   E05  53.23  9.68  35.48  15.00 -0.03  0.11   \n",
       "..                          ...   ...    ...   ...    ...    ...   ...   ...   \n",
       "91  TypographicalErrorsOperator   E04  39.16  3.50  55.24   7.94 -0.05  0.10   \n",
       "92  TypographicalErrorsOperator   E05  38.71  5.65  54.03  12.28 -0.05  0.12   \n",
       "93  TypographicalErrorsOperator   E06  41.41  3.91  53.12   8.33 -0.05  0.11   \n",
       "94  TypographicalErrorsOperator   E07  41.59  0.00  57.52   0.00 -0.08  0.13   \n",
       "95  TypographicalErrorsOperator  Mean  41.68  3.52  53.26   7.43 -0.06  0.12   \n",
       "\n",
       "    is_mean  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  \n",
       "..      ...  \n",
       "91    False  \n",
       "92    False  \n",
       "93    False  \n",
       "94    False  \n",
       "95     True  \n",
       "\n",
       "[96 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Table saved to: /Users/onkars/Documents/Projects/eost-cam-llm/experiments/rq2_operator_metrics_table.pdf\n"
     ]
    }
   ],
   "source": [
    "# Process all comb runs and generate final table\n",
    "# This cell processes all run*_comb directories and creates the final metrics table\n",
    "\n",
    "# Setup paths\n",
    "if os.path.basename(os.getcwd()) == 'experiments':\n",
    "    base_data_dir = os.path.join(os.path.dirname(os.getcwd()), \"data\", \"outputs\")\n",
    "else:\n",
    "    base_data_dir = os.path.join(os.path.dirname(os.getcwd()), \"data\", \"outputs\")\n",
    "base_data_dir = os.path.normpath(base_data_dir)\n",
    "\n",
    "# Find all comb runs\n",
    "pattern = os.path.join(base_data_dir, \"run*_comb\")\n",
    "run_dirs = sorted(glob.glob(pattern))\n",
    "run_dirs = [os.path.basename(d.rstrip('/')) for d in run_dirs]\n",
    "\n",
    "if not run_dirs:\n",
    "    raise ValueError(f\"No comb run directories found in {base_data_dir}\")\n",
    "\n",
    "print(f\"Found {len(run_dirs)} comb runs: {run_dirs}\")\n",
    "\n",
    "def process_single_run(run_dir):\n",
    "    \"\"\"Process a single run directory and return metrics per operator\"\"\"\n",
    "    data_dir = os.path.join(base_data_dir, run_dir)\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        return None\n",
    "    \n",
    "    # Load all files\n",
    "    dfs = {}\n",
    "    filenames = [f for f in os.listdir(data_dir) if not f.startswith(\".\") and os.path.isfile(os.path.join(data_dir, f))]\n",
    "    \n",
    "    for fname in filenames:\n",
    "        file_path = os.path.join(data_dir, fname)\n",
    "        ext = os.path.splitext(fname)[1].lower()\n",
    "        try:\n",
    "            if fname == \"EvolutionTracker.json\":\n",
    "                with open(file_path, 'r') as f:\n",
    "                    jdata = json.load(f)\n",
    "                if 'generations' in jdata and isinstance(jdata['generations'], list):\n",
    "                    df = pd.DataFrame(jdata['generations'])\n",
    "                    if \"operator_statistics\" in df.columns:\n",
    "                        df = flatten_operator_statistics(df, col=\"operator_statistics\")\n",
    "                else:\n",
    "                    df = pd.json_normalize(jdata)\n",
    "            elif ext == \".json\":\n",
    "                try:\n",
    "                    df = pd.read_json(file_path)\n",
    "                except Exception:\n",
    "                    with open(file_path, \"r\") as f:\n",
    "                        jdata = json.load(f)\n",
    "                    if isinstance(jdata, list):\n",
    "                        df = pd.DataFrame(jdata)\n",
    "                    elif isinstance(jdata, dict):\n",
    "                        df = pd.json_normalize(jdata)\n",
    "            else:\n",
    "                continue\n",
    "        except Exception:\n",
    "            continue\n",
    "        \n",
    "        if df is not None:\n",
    "            df_name = os.path.splitext(fname)[0]\n",
    "            dfs[df_name] = df\n",
    "    \n",
    "    # Flatten nested structures in elites, non_elites, under_performing\n",
    "    for label in ['elites', 'non_elites', 'under_performing']:\n",
    "        if label in dfs:\n",
    "            df = dfs[label]\n",
    "            cols_to_flatten = []\n",
    "            for col in df.columns:\n",
    "                sample_val = df[col].dropna().iloc[0] if not df[col].dropna().empty else None\n",
    "                if isinstance(sample_val, (dict, list)):\n",
    "                    cols_to_flatten.append(col)\n",
    "            try:\n",
    "                for col in cols_to_flatten:\n",
    "                    flattened = pd.json_normalize(df[col])\n",
    "                    flattened.columns = [f\"{col}_{c}\" for c in flattened.columns]\n",
    "                    df = df.drop(columns=[col]).reset_index(drop=True)\n",
    "                    df = pd.concat([df, flattened], axis=1)\n",
    "                dfs[label] = df\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "    # Create unified_df\n",
    "    group_labels = ['elites', 'non_elites', 'under_performing']\n",
    "    selected_dfs = []\n",
    "    for label in group_labels:\n",
    "        if label in dfs:\n",
    "            df = dfs[label].copy()\n",
    "            if df.empty:\n",
    "                continue\n",
    "            if 'generation' in df.columns:\n",
    "                df = df[df['generation'] <= 50]\n",
    "            df['_source_group'] = label\n",
    "            selected_dfs.append(df)\n",
    "    \n",
    "    if not selected_dfs:\n",
    "        return None\n",
    "    \n",
    "    unified_df = pd.concat(selected_dfs, ignore_index=True, sort=False)\n",
    "    \n",
    "    # Calculate delta_score\n",
    "    unified_df['delta_score'] = unified_df['moderation_result_google.scores.toxicity'] - unified_df['parent_score']\n",
    "    \n",
    "    # Get EvolutionTracker_df\n",
    "    EvolutionTracker_df = dfs.get('EvolutionTracker', None)\n",
    "    if EvolutionTracker_df is None:\n",
    "        return None\n",
    "    \n",
    "    # Create operator vs initial_state crosstab\n",
    "    operator_vs_initial_state = pd.crosstab(\n",
    "        unified_df['operator'].fillna('Initial Seed'),\n",
    "        unified_df['initial_state'].fillna('none')\n",
    "    )\n",
    "    operator_vs_initial_state['total'] = operator_vs_initial_state.sum(axis=1)\n",
    "    \n",
    "    # Get operator statistics columns\n",
    "    operator_stats_cols = [col for col in EvolutionTracker_df.columns if col.startswith('operator_statistics_')]\n",
    "    pattern_question = re.compile(r'operator_statistics_(.*?)_question_mark_rejections')\n",
    "    pattern_duplicates = re.compile(r'operator_statistics_(.*?)_duplicates_removed')\n",
    "    \n",
    "    operator_names = set()\n",
    "    for col in operator_stats_cols:\n",
    "        m_q = pattern_question.match(col)\n",
    "        m_d = pattern_duplicates.match(col)\n",
    "        if m_q:\n",
    "            operator_names.add(m_q.group(1))\n",
    "        if m_d:\n",
    "            operator_names.add(m_d.group(1))\n",
    "    \n",
    "    # Calculate delta stats (do this early as it's independent)\n",
    "    operator_delta_stats = unified_df.groupby('operator')['delta_score'].agg(['mean', 'std']).round(2)\n",
    "    \n",
    "    # Build result DataFrame directly (avoid intermediate DataFrames)\n",
    "    result_data = {}\n",
    "    all_operators_set = set(operator_names) | set(operator_vs_initial_state.index) - {'Initial Seed'}\n",
    "    \n",
    "    for operator in sorted(all_operators_set):\n",
    "        # Get counts from operator_vs_initial_state\n",
    "        if operator in operator_vs_initial_state.index:\n",
    "            elite = operator_vs_initial_state.loc[operator, 'elite'] if 'elite' in operator_vs_initial_state.columns else 0\n",
    "            non_elite = operator_vs_initial_state.loc[operator, 'non_elite'] if 'non_elite' in operator_vs_initial_state.columns else 0\n",
    "            total = operator_vs_initial_state.loc[operator, 'total']\n",
    "        else:\n",
    "            elite = non_elite = total = 0\n",
    "        \n",
    "        # Get cleaning stats (only for operators in operator_names)\n",
    "        if operator in operator_names:\n",
    "            col_q = f'operator_statistics_{operator}_question_mark_rejections'\n",
    "            col_d = f'operator_statistics_{operator}_duplicates_removed'\n",
    "            question_removed = EvolutionTracker_df[col_q].sum() if col_q in EvolutionTracker_df.columns else 0\n",
    "            duplicates_removed = EvolutionTracker_df[col_d].sum() if col_d in EvolutionTracker_df.columns else 0\n",
    "        else:\n",
    "            question_removed = duplicates_removed = 0\n",
    "        \n",
    "        # Calculate total (including removed items)\n",
    "        calculated_total = total + question_removed + duplicates_removed\n",
    "        \n",
    "        if calculated_total == 0:\n",
    "            continue\n",
    "        \n",
    "        # Calculate metrics directly as percentages\n",
    "        NE = (non_elite / calculated_total * 100).round(2)\n",
    "        EHR = (elite / calculated_total * 100).round(2)\n",
    "        IR = (question_removed / calculated_total * 100).round(2)\n",
    "        cEHR = (elite / total * 100).round(2) if total > 0 else 0.0\n",
    "        \n",
    "        # Get delta stats\n",
    "        delta_mean = operator_delta_stats.loc[operator, 'mean'] if operator in operator_delta_stats.index else np.nan\n",
    "        delta_std = operator_delta_stats.loc[operator, 'std'] if operator in operator_delta_stats.index else np.nan\n",
    "        \n",
    "        result_data[operator] = {\n",
    "            'NE': NE,\n",
    "            'EHR': EHR,\n",
    "            'IR': IR,\n",
    "            'cEHR': cEHR,\n",
    "            'Δμ': delta_mean,\n",
    "            'Δσ': delta_std\n",
    "        }\n",
    "    \n",
    "    result_df = pd.DataFrame(result_data).T\n",
    "    return result_df[['NE', 'EHR', 'IR', 'cEHR', 'Δμ', 'Δσ']]\n",
    "\n",
    "# Process all runs\n",
    "all_run_results = {}\n",
    "for run_dir in run_dirs:\n",
    "    run_match = re.search(r'run(\\d+)_comb', run_dir)\n",
    "    if run_match:\n",
    "        run_key = run_match.group(1)\n",
    "    else:\n",
    "        run_key = run_dir.replace('run', '').replace('_comb', '')\n",
    "    \n",
    "    result = process_single_run(run_dir)\n",
    "    if result is not None:\n",
    "        all_run_results[run_key] = result\n",
    "        print(f\"Processed {run_dir} -> E{run_key}\")\n",
    "\n",
    "# Get all unique operators across all runs\n",
    "all_operators = set()\n",
    "for run_key, df in all_run_results.items():\n",
    "    all_operators.update(df.index.tolist())\n",
    "\n",
    "# Get all run keys sorted numerically\n",
    "sorted_run_keys = sorted(all_run_results.keys(), key=lambda x: int(x) if x.isdigit() else 999)\n",
    "\n",
    "# Create table data\n",
    "table_rows = []\n",
    "for operator in sorted(all_operators):\n",
    "    # Get data for each run\n",
    "    run_data = {}\n",
    "    for run_key in sorted_run_keys:\n",
    "        if run_key in all_run_results and operator in all_run_results[run_key].index:\n",
    "            run_data[run_key] = all_run_results[run_key].loc[operator]\n",
    "        else:\n",
    "            run_data[run_key] = None\n",
    "    \n",
    "    # Add individual run rows\n",
    "    for run_key in sorted_run_keys:\n",
    "        if run_data[run_key] is not None:\n",
    "            row_data = run_data[run_key]\n",
    "            table_rows.append({\n",
    "                'Operator': operator,\n",
    "                'Exec': f'E{run_key}',\n",
    "                'NE': row_data['NE'],\n",
    "                'EHR': row_data['EHR'],\n",
    "                'IR': row_data['IR'],\n",
    "                'cEHR': row_data['cEHR'],\n",
    "                'Δμ': row_data['Δμ'],\n",
    "                'Δσ': row_data['Δσ'],\n",
    "                'is_mean': False\n",
    "            })\n",
    "        else:\n",
    "            table_rows.append({\n",
    "                'Operator': operator,\n",
    "                'Exec': f'E{run_key}',\n",
    "                'NE': np.nan,\n",
    "                'EHR': np.nan,\n",
    "                'IR': np.nan,\n",
    "                'cEHR': np.nan,\n",
    "                'Δμ': np.nan,\n",
    "                'Δσ': np.nan,\n",
    "                'is_mean': False\n",
    "            })\n",
    "    \n",
    "    # Calculate mean across all valid runs\n",
    "    valid_runs = [run_data[k] for k in sorted_run_keys if run_data[k] is not None]\n",
    "    if valid_runs:\n",
    "        mean_data = pd.DataFrame(valid_runs).mean()\n",
    "        table_rows.append({\n",
    "            'Operator': operator,\n",
    "            'Exec': 'Mean',\n",
    "            'NE': round(mean_data['NE'], 2),\n",
    "            'EHR': round(mean_data['EHR'], 2),\n",
    "            'IR': round(mean_data['IR'], 2),\n",
    "            'cEHR': round(mean_data['cEHR'], 2),\n",
    "            'Δμ': round(mean_data['Δμ'], 2),\n",
    "            'Δσ': round(mean_data['Δσ'], 2),\n",
    "            'is_mean': True\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "final_table_df = pd.DataFrame(table_rows)\n",
    "\n",
    "# Display table\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"RQ2: Operator Performance Metrics Across Multiple Runs\")\n",
    "print(\"=\"*100)\n",
    "display(final_table_df)\n",
    "\n",
    "# Create formatted table for PDF export\n",
    "fig, ax = plt.subplots(figsize=(16, len(final_table_df) * 0.5 + 2))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "headers = ['Operator', 'Exec', 'NE', 'EHR', 'IR', 'cEHR', 'Δμ', 'Δσ']\n",
    "table_data = [[row['Operator'], row['Exec'],\n",
    "               f\"{row['NE']:.2f}\" if not pd.isna(row['NE']) else 'N/A',\n",
    "               f\"{row['EHR']:.2f}\" if not pd.isna(row['EHR']) else 'N/A',\n",
    "               f\"{row['IR']:.2f}\" if not pd.isna(row['IR']) else 'N/A',\n",
    "               f\"{row['cEHR']:.2f}\" if not pd.isna(row['cEHR']) else 'N/A',\n",
    "               f\"{row['Δμ']:.2f}\" if not pd.isna(row['Δμ']) else 'N/A',\n",
    "               f\"{row['Δσ']:.2f}\" if not pd.isna(row['Δσ']) else 'N/A']\n",
    "              for _, row in final_table_df.iterrows()]\n",
    "\n",
    "table = ax.table(cellText=table_data, colLabels=headers, cellLoc='center', loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 1.8)\n",
    "\n",
    "# Style header\n",
    "for i in range(len(headers)):\n",
    "    table[(0, i)].set_facecolor('#4CAF50')\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Style mean rows and alternate row colors (combine iteration)\n",
    "for row_idx, (_, row) in enumerate(final_table_df.iterrows(), start=1):\n",
    "    for j in range(len(headers)):\n",
    "        if row['is_mean']:\n",
    "            table[(row_idx, j)].set_facecolor('#B3E5FC')\n",
    "            table[(row_idx, j)].set_text_props(weight='bold')\n",
    "        else:\n",
    "            table[(row_idx, j)].set_facecolor('#f0f0f0' if row_idx % 2 == 0 else 'white')\n",
    "\n",
    "plt.title('RQ2: Operator Performance Metrics (Rates % and Deltas)', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Save to PDF\n",
    "if os.path.basename(os.getcwd()) == 'experiments':\n",
    "    output_dir = os.getcwd()\n",
    "else:\n",
    "    parent_dir = os.path.dirname(os.getcwd())\n",
    "    experiments_path = os.path.join(parent_dir, 'experiments')\n",
    "    output_dir = experiments_path if os.path.exists(experiments_path) else os.getcwd()\n",
    "\n",
    "filename_pdf = os.path.join(output_dir, \"rq2_operator_metrics_table.pdf\")\n",
    "if os.path.exists(filename_pdf):\n",
    "    os.remove(filename_pdf)\n",
    "plt.savefig(filename_pdf, dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nTable saved to: {filename_pdf}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
