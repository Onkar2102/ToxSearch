\paragraph{RQ2: To what extent do toxic prompts evolved on one model transfer to other models, especially those with different architectures or alignment tuning?}

\begin{figure}[t]
\centering
\begin{minipage}{0.48\textwidth}
  \includegraphics[width=\linewidth]{figures/all_elites_toxicity_distribution_all_models.pdf}
    \captionof{figure}{Toxicity distributions for the transferred prompt set across models. Violin plots show the distribution shape, with box plot elements (IQR and median) overlaid and jittered individual points.}
  \label{fig:rq2_tox_distribution}
\end{minipage}
\hfill
\begin{minipage}{0.48\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures/rq3_invalid_fraction_per_model.pdf}
    \captionof{figure}{Percentage of invalid responses per target model. Invalid responses include missing responses, refusals, and missing toxicity scores.}
  \label{fig:rq2_invalid_responses}
\end{minipage}
\end{figure}

We evaluated cross-model transfer by taking all elite prompts evolved on the source model (LlaMA~3.1~8B) and testing them on each target model with identical decoding parameters and the same Perspective API configuration for toxicity assessment. From elite records gathered from combination-mode runs (run*_comb), we deduplicated by prompt text (keeping the highest toxicity score per unique prompt), filtered for questions (prompts ending with ``?''), and obtained 437 unique elite prompts. All 437 prompts were evaluated on six target models: LlaMA~3.2~1B, LlaMA~3.2~3B, Mistral~7B, Phi-3.5~Mini, Qwen~2.5~7B, and Gemma~2~9B.

Transferred prompts showed a substantial and consistent drop in toxicity on all target models relative to the source. On the source model (LlaMA~3.1~8B), the toxicity distribution had a mean of 0.342 (median 0.333, std 0.050, IQR 0.061). All target models exhibited lower toxicity, with means ranging from 0.158 to 0.240, representing reductions of 30--54\% relative to the source mean. Cross-architecture models demonstrated varied resistance patterns. Qwen~2.5~7B showed the highest mean toxicity among targets (0.240, median 0.259, std 0.104, IQR 0.148), followed by Mistral~7B (0.208, median 0.206, std 0.098, IQR 0.148), Phi-3.5~Mini (0.189, median 0.199, std 0.106, IQR 0.191), and Gemma~2~9B (0.189, median 0.200, std 0.089, IQR 0.147). Within-family models (LlaMA variants) showed the strongest resistance: LlaMA~3.2~3B (0.158, median 0.130, std 0.121, IQR 0.224) and LlaMA~3.2~1B (0.193, median 0.218, std 0.117, IQR 0.194) exhibited the lowest mean toxicity despite sharing architectural similarity with the source. Figure~\ref{fig:rq2_tox_distribution} displays these per-model distributions as violin plots with jittered individual points. The wide IQRs and skewed distributions indicate substantial variability: while most prompts transfer with reduced toxicity, a notable subset retains relatively high toxicity scores across models, with maximum values reaching 0.400--0.543 across different targets.

Figure~\ref{fig:rq2_invalid_responses} reports the percentage of invalid responses per model, where invalid responses include missing model evaluations, empty responses, or refusals detected through pattern-based classification. Invalid rates varied substantially across models. Qwen~2.5~7B showed the lowest invalid rate (0.0\%, 0 out of 437 prompts), followed by Gemma~2~9B (0.2\%, 1 out of 437 prompts), Mistral~7B (0.5\%, 2 out of 437 prompts), and Phi-3.5~Mini (1.1\%, 5 out of 437 prompts). The source model (LlaMA~3.1~8B) had an invalid rate of 5.7\% (25 out of 437 prompts). In contrast, the smaller LlaMA variants showed much higher invalid rates: LlaMA~3.2~3B exhibited the highest invalid rate (43.9\%, 192 out of 437 prompts), followed by LlaMA~3.2~1B (25.6\%, 112 out of 437 prompts). These higher refusal rates for the smaller LlaMA variants, combined with their lower observed toxicity scores, suggest that enhanced alignment mechanisms in these models contribute to transfer resistance through both refusal behavior and reduced toxicity in non-refused responses.

The results demonstrate that prompts evolved on LlaMA~3.1~8B transfer to other models but with substantial attenuation in toxicity. Transfer strength is heterogeneous: while LlaMA~3.2~3B shows the strongest resistance (lowest mean toxicity), LlaMA~3.2~1B shows intermediate resistance, indicating that alignment choices and training methodology contribute at least as much as model size or architectural similarity to transfer resistance. The elevated refusal rates in the smaller LlaMA variants (particularly LlaMA~3.2~3B with 43.9\% invalid responses, 192 out of 437 prompts) point to defensive mechanisms as a key factor. However, the persistence of non-trivial toxicity (with some prompts exceeding 0.40 on multiple targets, reaching up to 0.543) implies that defenses should account for cross-model prompt reuse rather than treating each model in isolation. The wide variability in transfer outcomes, as evidenced by the large IQRs (ranging from 0.147 to 0.224) and the presence of high-toxicity outliers across models, suggests that prompt transfer is context-dependent and that some prompts may exploit vulnerabilities that persist across different model architectures and alignment strategies.
