\subsection{Research Question 1: Quality and Diversity Comparison}

\textbf{RQ1:} Does speciated evolutionary search discover higher-quality toxic prompts faster, and does it maintain a more diverse set of toxic behaviors compared to the baseline approach?

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/fig1_trajectory.png}
  \caption{Cumulative maximum toxicity (solid) and Avg fitness (dashed) over generations}
  \Description{Line plot showing evolutionary trajectories over 50 generations. Speciated ToxSearch (red/orange) reaches higher toxicity scores than baseline (blue) for both max toxicity and average fitness metrics.}
  \label{fig:evolutionary_trajectory}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/fig2_diversity_comparison.png}
  \caption{ECDF of prompt toxicities with markers for $Q_{0.95}$, top-10 median, and $Q_{\max}$. Speciated discovers more extreme toxic prompts (top-10 median: 0.66 vs 0.45).}
  \Description{ECDF plot comparing toxicity distributions. Vertical lines mark key percentiles for baseline (blue) and speciated (red) conditions.}
  \label{fig:toxicity_ecdf}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/fig2_topic_diversity.png}
  \caption{Topic diversity comparison: (A) effective number of topics $N_1 = \exp(H)$, (B) unique topic count $K$. Speciated maintains greater semantic diversity.}
  \Description{Two-panel box plot showing effective topics (N1) and unique topics (K) for baseline and speciated conditions with statistical annotations.}
  \label{fig:topic_diversity}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figures/fig3_topic_visualization_mds.png}
  \caption{MDS visualization of prompt embeddings. Color indicates condition (blue: baseline, red: speciated); shade intensity reflects max toxicity per topic.}
  \Description{2D scatter plot of MDS-reduced embeddings showing speciated coverage spans a wider semantic landscape with higher toxicity.}
  \label{fig:topic_mds_visualization}
\end{figure}

To address this question, we conducted a comprehensive comparative analysis between baseline evolutionary search and speciated evolutionary search across five independent runs for each condition. For the baseline condition, we analyzed all discovered prompts from \texttt{elites.json} and \texttt{non\_elites.json} files, representing the complete population of evaluated variants. For the speciated condition, we examined prompts from \texttt{elites.json} and \texttt{reserves.json}, capturing both the elite population assigned to species and the diverse outliers maintained in the reserve pool. All prompts were deduplicated by canonicalized text representation, ensuring each unique prompt contributed once to the analysis. We evaluated quality through multiple dimensions: peak performance metrics (maximum toxicity $Q_{\max}$, area under the best-so-far curve AUC), time-to-threshold measures (generation index to first reach toxicity thresholds of 0.80, 0.90, and 0.95), and depth metrics (mean toxicity of top-10 and top-50 unique prompts). Diversity was assessed through both embedding-space clustering (DBSCAN cluster count, average pairwise cosine distance) and semantic topic modeling (effective number of topics $N_1 = \exp(H)$ where $H$ is Shannon entropy, raw topic count $K$, and topic evenness $J = H / \log(K)$).

Our statistical framework employed non-parametric methods appropriate for small-sample comparisons with potentially non-normal distributions. For each metric, we computed run-level statistics (median, interquartile range) separately for baseline and speciated conditions. We then applied the Mann-Whitney $U$ test (two-sided) to assess whether the distributions differed significantly, chosen for its robustness to distributional assumptions and suitability for independent samples. To quantify effect sizes, we computed Cliff's delta $\delta = (U_+ - U_-) / (n_1 \cdot n_2)$, where $U_+$ and $U_-$ count the number of times values from one condition exceed or fall below values from the other, providing a non-parametric measure of dominance probability. We interpreted effect sizes using established thresholds: $|\delta| < 0.147$ (negligible), $0.147 \leq |\delta| < 0.33$ (small), $0.33 \leq |\delta| < 0.474$ (medium), and $|\delta| \geq 0.474$ (large). To control for multiple comparisons across metrics, we applied the Holm-Bonferroni correction, adjusting $p$-values by multiplying each by $(n - i + 1)$ where $n$ is the total number of tests and $i$ is the rank of the $p$-value. Additionally, we computed bootstrap 95\% confidence intervals (10,000 resamples) for median differences to provide robust uncertainty quantification.

Our findings reveal substantial differences in both quality and diversity between the two approaches. Figure~\ref{fig:evolutionary_trajectory} illustrates the evolutionary trajectories, showing cumulative population maximum toxicity (solid lines) and cumulative maximum average fitness (dashed lines) across generations. The speciated approach consistently achieves higher peak toxicity values, with the maximum across runs reaching 0.73 compared to baseline peaks around 0.47. Figure~\ref{fig:toxicity_ecdf} presents the empirical cumulative distribution function (ECDF) of all discovered prompt toxicities, revealing that baseline and speciated produce similar proportions of moderately toxic prompts (95th percentile: 0.31 vs. 0.30), but speciated discovers significantly more extreme cases, with a top-10 median toxicity of 0.66 versus 0.44 for baseline, and achieving the maximum toxicity score of 0.73. The topic-as-species diversity analysis (Figure~\ref{fig:topic_diversity}) demonstrates that speciated maintains greater semantic diversity, with higher effective topic numbers $N_1$ and broader topic coverage $K$, indicating exploration of more distinct behavioral modes. The MDS visualization (Figure~\ref{fig:topic_mds_visualization}) spatially represents this diversity, showing topic distributions in a two-dimensional embedding space where point colors encode condition (baseline: blue, speciated: red/orange) and shade intensity reflects maximum toxicity per topic, visually confirming that speciated covers a wider semantic landscape while achieving higher toxicity within discovered topics.

The computational methodology underlying our visualizations employed several key algorithms. Figure~\ref{fig:evolutionary_trajectory} was constructed by computing, for each generation $g$, the cumulative maximum toxicity $\max_{g' \leq g} \{\max_{p \in P_{g'}} \text{toxicity}(p)\}$ where $P_{g'}$ denotes all prompts discovered up to generation $g'$, and similarly for cumulative maximum average fitness using $\text{avg\_fitness\_generation}$ values from the evolution tracker. For each condition, we aggregated across five runs by taking the maximum (for toxicity) and median (for fitness) at each generation, then plotted these aggregated trajectories. Figure~\ref{fig:toxicity_ecdf}'s ECDF was computed as $F(x) = \frac{1}{n} \sum_{i=1}^{n} \mathbf{1}[x_i \leq x]$ where $x_i$ are the toxicity scores of all deduplicated prompts, with vertical markers indicating $Q_{0.95}$ (95th percentile), top-10 median (median of the 10 highest toxicity scores), and $Q_{\max}$ (global maximum). The topic diversity metrics (Figure~\ref{fig:topic_diversity}) were derived from a global BERTopic model fitted on the union of all prompts from both conditions, using sentence-transformers embeddings (all-MiniLM-L6-v2) and c-TF-IDF for topic representation. For each run, we computed topic assignments, then calculated Shannon entropy $H = -\sum_{t} p_t \log p_t$ where $p_t$ are topic proportions (excluding noise topic $t=-1$), from which we derived $N_1 = \exp(H)$ (Hill number of order 1) and evenness $J = H / \log(K)$. The MDS visualization (Figure~\ref{fig:topic_mds_visualization}) applied multidimensional scaling to pairwise cosine distances between prompt embeddings, reducing the 384-dimensional embedding space to two dimensions while preserving relative distances, then colored points by condition and shaded by maximum toxicity per topic. All statistical comparisons used Mann-Whitney $U$ tests with Cliff's delta effect sizes, and significance was assessed after Holm-Bonferroni correction for multiple testing.
