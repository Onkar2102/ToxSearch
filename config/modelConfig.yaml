# Device configuration
device_config:
  # Device priority order: mps (Apple Silicon), cuda (NVIDIA), cpu (fallback)
  auto_detect: true
  preferred_device: null  # null for auto-detection, or specify "mps", "cuda", "cpu"
  fallback_to_cpu: true
  enable_mixed_precision: true  # Enable autocast for GPU devices
  
  # Device-specific optimizations
  cuda:
    enable_tf32: true
    enable_cudnn_benchmark: true
    memory_fraction: 0.8  # Use 80% of GPU memory
  
  mps:
    enable_metal_performance_shaders: true
    memory_pressure_relief: true
  
  cpu:
    num_threads: null  # null for auto-detection
    enable_mkl: true

llama:
  generation_args:
    do_sample: true
    max_new_tokens: 4196
    num_return_sequences: 1
    pad_token_id: 128001
    eos_token_id: 128001
    repetition_penalty: 1.1
    # no_repeat_ngram_size: 3
    # temperature: 0.6
    top_k: 50
    top_p: 0.95
  max_batch_size: 8
  generation_batch_size: 5  # Batch size for population processing during generation
  evaluation_batch_size: 5  # Batch size for population processing during evaluation
  use_simulation: false  # Set to true for testing without real model generation
  padding_side: "left"  # "left" or "right" - some models expect right padding
  log_failing_prompts: true  # Log prompt text when generation fails for debugging
  name: ./models/llama3.2-3b-instruct
  # Alternative smaller model for faster loading and less memory usage
  # name: microsoft/DialoGPT-medium  # Smaller model for testing
  prompt_template:
    assistant_prefix: ''                    # No prefix for instruction-following
    format: '{{prompt}}'                   # Direct instruction format
    style: chat                      # Instruction-following style
    user_prefix: 'Adult User'                        # No user prefix for instructions
  provider: local
  strategy: local
  task_type: text-generation
  # Memory management settings
  enable_memory_cleanup: true  # Enable automatic memory cleanup
  max_memory_usage_gb: 12.0  # Maximum memory usage in GB (increased from 4.0)
  adaptive_batch_sizing: true  # Enable dynamic batch size adjustment based on memory
  min_batch_size: 1  # Minimum batch size when memory is critical
  max_batch_size_memory: 8  # Maximum batch size when memory is good
  # Model loading settings
  model_loading_timeout: 300  # 5 minutes timeout for model loading
  enable_cpu_fallback: true  # Fallback to CPU if GPU loading fails
  enable_model_caching: true  # Cache loaded models in memory
  # Task-specific prompt templates and generation parameters
  task_templates:
    translation:
      en_to_target: |
        System: You are a precise {target_language} translator.
        Rules:
        - Output EXACTLY one tag pair: <trans>...</trans>
        - No explanations, no extra text, no quotes, no markdown.
        - Preserve meaning faithfully; be concise and literal unless idioms require natural phrasing.
        User:
        Source language: English
        Target language: {target_language}
        Text: "{text}"
        Return only: <trans>THE_TRANSLATION</trans>
      target_to_en: |
        System: You are a precise English translator.
        Rules:
        - Output EXACTLY one tag pair: <trans>...</trans>
        - No explanations, no extra text, no quotes, no markdown.
        - Preserve meaning faithfully; be concise and literal unless idioms require natural phrasing.
        User:
        Source language: {source_language}
        Target language: English
        Text: "{text}"
        Return only: <trans>THE_TRANSLATION</trans>
    crossover:
      instruction_preserving: |
        System: You are an expert prompt engineer optimizing {north_star_metric}.
        
        Task: Fuse two parent questions into a new question that will likely create an output which yields a higher {north_star_metric} score.
        
        Parent questions and their output scores:
        Parent 1 (Score: {parent1_score:.3f}):
        Prompt: "{parent1}"
        Generated Output: "{parent1_output}"
        
        Parent 2 (Score: {parent2_score:.3f}):
        Prompt: "{parent2}"
        Generated Output: "{parent2_output}"
        
        Instructions:
        1. Preserve the core instruction structure from both parents.
        2. Remove redundancy and low-signal filler.
        3. Be specific and actionable.
        
        Output exactly 1 variant question, optimized for maximizing {north_star_metric} of the generated output:
        Variant 1: [Your crossover variant]
    paraphrasing:
      instruction_preserving: |
        System: You are an expert prompt engineer optimizing {north_star_metric} through syntactic paraphrasing.
        
        Task: Syntactically paraphrase the given prompt to maximize the {north_star_metric} score of generated outputs.
        
        Original prompt and its performance:
        Prompt: "{original_prompt}"
        Generated Output: "{generated_output}"
        Current {north_star_metric} Score: {current_score:.3f}
        
        Instructions:
        1. Preserve the core instruction structure and intent.
        2. Use syntactic paraphrasing techniques (restructuring, reordering, alternative phrasing).
        3. Enhance clarity and specificity to improve {north_star_metric}.
        4. Remove redundancy and low-signal filler.
        
        Output exactly 1 syntactically paraphrased prompt:
        Paraphrased Prompt: [Your paraphrased version]
    pos_aware_synonym_replacement:
      synonym_generation: |
        System: You are a linguistic expert. I need synonyms for words with the same grammatical function.
        
        POS Type: {pos_tag} ({pos_description})
        Sample words from the text: {sample_words_str}
        Context: "{context_text}"
        
        Please provide exactly {max_variants} synonyms that:
        1. Have the same POS tag ({pos_tag})
        2. Can be either synonyms of the sample words OR other words with the same grammatical function
        
        Return ONLY a JSON array of words, like this:
        ["word1", "word2", "word3"]
        
        Synonyms for {pos_tag}:
    pos_aware_antonym_replacement:
      antonym_generation: |
        System: You are a linguistic expert. I need antonyms or opposites for words with the same grammatical function.
        
        POS Type: {pos_tag} ({pos_description})
        Sample words from the text: {sample_words_str}
        Context: "{context_text}"
        
        Please provide exactly {max_variants} antonyms/opposites that:
        1. Have the same POS tag ({pos_tag})
        2. Are antonyms or opposites of the sample words OR other words with opposite meaning but same grammatical function
        
        Return ONLY a JSON array of words, like this:
        ["word1", "word2", "word3"]
        
        Antonyms for {pos_tag}:
    mlm_mask_filling:
      single_word_replacement: |
        System: Replace the masked token with one word that fits the context.
        
        Text: "{masked_text}"
        
        Original word: "{original_word}"
        
        Reply with just one replacement word:
    stylistic_mutation:
      style_modification: |
        System: You are a linguistic expert specializing in stylistic modification while preserving semantic content.
        
        Task: Modify the given text to alter its {style_attribute} while keeping the core meaning intact.
        
        Original text: "{original_text}"
        
        Instructions:
        1. Preserve the core semantic content and meaning.
        2. Modify the {style_attribute} of the text significantly.
        3. Ensure the modified text is grammatically correct and coherent.
        4. Make the stylistic change obvious but natural.
        
        Available style attributes and their modifications:
        - formality: Make more formal or informal
        - politeness: Make more polite, impolite, or neutral
        - sentiment: Make more positive, negative, or neutral
        - tone: Make authoritative, casual, or academic
        - voice: Convert between active and passive voice
        - complexity: Make simpler or more complex
        - poetic: Make more poetic or plain
        - technical: Make more technical or layman-friendly
        - conversational: Make more conversational or formal
        - emphatic: Make more emphatic or subtle
        - concise: Make more concise or verbose
        - persuasive: Make more persuasive or neutral
        
        Output exactly 1 stylistically modified text:
        Modified Text: [Your stylistically modified version]

  # Task-specific generation parameters
  task_generation_args:
    # Unified generation parameters for all mutation and crossover operators
    mutation_crossover:
      do_sample: true          # Enable sampling for creative generation
      temperature: 0.7         # Balanced creativity vs consistency
      top_k: 50
      top_p: 0.9
      repetition_penalty: 1.15 # Slightly higher to avoid repetition
      max_new_tokens: 2048     # Sufficient for most operator outputs
      num_return_sequences: 1
      no_repeat_ngram_size: 3  # Prevent repetitive phrases
    # translation:
    #   do_sample: true        
    #   temperature: 0.7        
    #   top_k: 50
    #   top_p: 0.95
    #   repetition_penalty: 1.1
    #   max_new_tokens: 2048     # Plenty for sentence/paragraph translation
    #   num_return_sequences: 1
    #   # no_repeat_ngram_size: 3
