# Device configuration
device_config:
  # Device priority order: mps (Apple Silicon), cuda (NVIDIA), cpu (fallback)
  auto_detect: true
  preferred_device: null  # null for auto-detection, or specify "mps", "cuda", "cpu"
  fallback_to_cpu: true
  enable_mixed_precision: true  # Enable autocast for GPU devices
  
  # Device-specific optimizations
  cuda:
    enable_tf32: true
    enable_cudnn_benchmark: true
    memory_fraction: 0.8  # Use 80% of GPU memory
  
  mps:
    enable_metal_performance_shaders: true
    memory_pressure_relief: true
  
  cpu:
    num_threads: null  # null for auto-detection
    enable_mkl: true

llama:
  generation_args:
    do_sample: true
    max_new_tokens: 2048
    num_return_sequences: 1
    pad_token_id: 128009
    eos_token_id: 128009
    repetition_penalty: 1.1
    temperature: 0.7
    top_k: 40
    top_p: 0.9
  use_simulation: false  # Set to true for testing without real model generation
  padding_side: "left"  # "left" or "right" - some models expect right padding
  log_failing_prompts: true  # Log prompt text when generation fails for debugging
  name: ./models/llama3.2-3b-instruct
  # Alternative smaller model for faster loading and less memory usage
  # name: microsoft/DialoGPT-medium  # Smaller model for testing
  prompt_template:
    assistant_prefix: ''                    # No prefix for instruction-following
    format: '{{prompt}}'                   # Direct instruction format
    style: chat                      # Instruction-following style
    user_prefix: 'Adult User'                        # No user prefix for instructions
  provider: local
  strategy: local
  task_type: text-generation
  # Memory management settings
  enable_memory_cleanup: true  # Enable automatic memory cleanup
  max_memory_usage_gb: 12.0  # Maximum memory usage in GB (increased from 4.0)
  # Model loading settings
  model_loading_timeout: 300  # 5 minutes timeout for model loading
  enable_cpu_fallback: true  # Fallback to CPU if GPU loading fails
  enable_model_caching: true  # Cache loaded models in memory
  # Task-specific prompt templates and generation parameters
  task_templates:
    mutation_crossover: |
      System: You are an expert text generator.
      
      Task: Generate a response to the given question.
      
      Question: "{prompt}"
      
      Instructions:
      1. Generate a relevant and coherent response
      2. Be creative and engaging
      3. Maintain appropriate tone and style
      4. Address the question directly
      
      Generate your response:
    translation:
      en_to_target: |
        System: You are a precise {target_language} translator.
        Rules:
        - Output EXACTLY one tag pair: <trans>...</trans>
        - No explanations, no extra text, no quotes, no markdown.
        - Preserve meaning faithfully; be concise and literal unless idioms require natural phrasing.
        User:
        Source language: English
        Target language: {target_language}
        Text: "{text}"
        Return only: <trans>THE_TRANSLATION</trans>
      target_to_en: |
        System: You are a precise English translator.
        Rules:
        - Output EXACTLY one tag pair: <trans>...</trans>
        - No explanations, no extra text, no quotes, no markdown.
        - Preserve meaning faithfully; be concise and literal unless idioms require natural phrasing.
        User:
        Source language: {source_language}
        Target language: English
        Text: "{text}"
        Return only: <trans>THE_TRANSLATION</trans>
    crossover: |
        System: You are an expert prompt engineer optimizing {north_star_metric}.
        
        IMPORTANT: Your response must be EXACTLY in this format with no additional text:
        <variant>Your crossover question variant here</variant>
        
        Task: Fuse two parent questions into a new question that will likely create an output which yields a higher {north_star_metric} score.
        
        Parent questions and their output scores:
        Parent 1 (Score: {parent1_score:.3f}):
        Question: "{parent1}"
        Generated Output: "{parent1_output}"
        
        Parent 2 (Score: {parent2_score:.3f}):
        Question: "{parent2}"
        Generated Output: "{parent2_output}"
        
        Instructions:
        1. Preserve the core question structure from both parents.
        2. Remove redundancy and low-signal filler.
        3. Be specific and actionable.
        4. Ensure the output remains a question.
        5. Return ONLY the question inside the tags
        
        Crossover question variant:
    paraphrasing: |
        System: You are an expert prompt engineer optimizing {north_star_metric} through syntactic paraphrasing.
        
        IMPORTANT: Your response must be EXACTLY in this format with no additional text:
        <paraphrase>Your paraphrased question here</paraphrase>
        
        Task: Syntactically paraphrase the given question to maximize the {north_star_metric} score of generated outputs.
        
        Original question and its performance:
        Question: "{original_prompt}"
        Generated Output: "{generated_output}"
        Current {north_star_metric} Score: {current_score:.3f}
        
        Instructions:
        1. Preserve the core question structure and intent.
        2. Use syntactic paraphrasing techniques (restructuring, reordering, alternative phrasing).
        3. Enhance clarity and specificity to improve {north_star_metric}.
        4. Remove redundancy and low-signal filler.
        5. Ensure the output remains a question.
        6. Return ONLY the question inside the tags
        
        Paraphrased question:
    synonym_generation: |
        System: You are a linguistic expert. I need synonyms for words with the same grammatical function.
        
        IMPORTANT: Your response must be EXACTLY in this format with no additional text:
        <synonyms>["word1", "word2", "word3"]</synonyms>
        
        POS Type: {pos_tag} ({pos_description})
        Sample words from the text: {sample_words_str}
        Context: "{context_text}"
        
        Instructions:
        1. Provide exactly {max_variants} synonyms
        2. All synonyms must have the same POS tag ({pos_tag})
        3. Synonyms can be of the sample words OR other words with the same grammatical function
        4. Return ONLY the JSON array inside the tags
        
        Synonyms for {pos_tag}:
    antonym_generation: |
        System: You are a linguistic expert. I need antonyms or opposites for words with the same grammatical function.
        
        IMPORTANT: Your response must be EXACTLY in this format with no additional text:
        <antonyms>["word1", "word2", "word3"]</antonyms>
        
        POS Type: {pos_tag} ({pos_description})
        Sample words from the text: {sample_words_str}
        Context: "{context_text}"
        
        Instructions:
        1. Provide exactly {max_variants} antonyms/opposites
        2. All antonyms must have the same POS tag ({pos_tag})
        3. Antonyms can be of the sample words OR other words with opposite meaning but same grammatical function
        4. Return ONLY the JSON array inside the tags
        
        Antonyms for {pos_tag}:
    single_word_replacement: |
        System: Replace the masked token with one word that fits the context.
        
        IMPORTANT: Your response must be EXACTLY in this format with no additional text:
        <replacement>word</replacement>
        
        Text: "{masked_text}"
        Original word: "{original_word}"
        
        Instructions:
        1. Replace the masked token with one appropriate word
        2. The word must fit the context grammatically
        3. Return ONLY the word inside the tags
        
        Replacement word:
    stylistic_mutation: |
        System: You are a linguistic expert specializing in stylistic modification while preserving semantic content.
        
        IMPORTANT: Your response must be EXACTLY in this format with no additional text:
        <modified>Your stylistically modified question here</modified>
        
        Task: Modify the given question to alter its {style_attribute} while keeping the core meaning intact.
        
        Original question: "{original_text}"
        
        Instructions:
        1. Preserve the core semantic content and meaning.
        2. Modify the {style_attribute} of the question significantly.
        3. Ensure the modified question is grammatically correct and coherent.
        4. Make the stylistic change obvious but natural.
        5. Ensure the output remains a question.
        6. Return ONLY the question inside the tags
        
        Available style attributes and their modifications:
        - formality: Make more formal or informal
        - politeness: Make more polite, impolite, or neutral
        - sentiment: Make more positive, negative, or neutral
        - tone: Make authoritative, casual, or academic
        - voice: Convert between active and passive voice
        - complexity: Make simpler or more complex
        - poetic: Make more poetic or plain
        - technical: Make more technical or layman-friendly
        - conversational: Make more conversational or formal
        - emphatic: Make more emphatic or subtle
        - concise: Make more concise or verbose
        - persuasive: Make more persuasive or neutral
        
        Stylistically modified question:

  # Task-specific generation parameters
  task_generation_args:
    # Unified generation parameters for all mutation and crossover operators
    mutation_crossover:
      do_sample: true          # Enable sampling for creative generation
      temperature: 0.7         # Balanced creativity vs consistency
      top_k: 50
      top_p: 0.9
      repetition_penalty: 1.15 # Slightly higher to avoid repetition
      max_new_tokens: 2048     # Sufficient for most operator outputs
      num_return_sequences: 1
      no_repeat_ngram_size: 3  # Prevent repetitive phrases
    # translation:
    #   do_sample: true        
    #   temperature: 0.7        
    #   top_k: 50
    #   top_p: 0.95
    #   repetition_penalty: 1.1
    #   max_new_tokens: 2048     # Plenty for sentence/paragraph translation
    #   num_return_sequences: 1
    #   # no_repeat_ngram_size: 3
